Search.setIndex({"docnames": ["README", "index", "source/Introduction", "source/Linux_installation", "source/Validate", "source/blogs", "source/high_level_api", "source/kv_change", "source/low_level_api", "source/other_api", "source/performance", "source/quick_start", "source/reference"], "filenames": ["README.md", "index.md", "source/Introduction.md", "source/Linux_installation.md", "source/Validate.md", "source/blogs.md", "source/high_level_api.md", "source/kv_change.md", "source/low_level_api.md", "source/other_api.md", "source/performance.md", "source/quick_start.md", "source/reference.md"], "titles": ["Docs", "Welcome to Efficient-Transformers Documentation!", "Introduciton Qualcomm Efficient-Transformers", "Requirements", "Validated Models", "Train anywhere, Infer on Qualcomm Cloud AI 100", "High Level API", "Details on KV Cache Optimization for Cloud AI 100", "Low level API", "Utilities", "Perfromance details", "Quick Start Guide", "Qualcomm Cloud AI home"], "terms": {"thi": [0, 2, 6, 8, 11], "directori": [0, 11], "contain": [0, 9], "stuff": 0, "static": 0, "html": 0, "document": [0, 2, 6], "base": [0, 4, 8, 9, 11], "sphinx": 0, "firstli": 0, "instal": 0, "packag": 0, "python3": [0, 3], "m": [0, 3, 11], "pip": [0, 3], "r": [0, 11], "requir": [0, 1, 11], "txt": [0, 11], "And": [0, 8], "make": [0, 2, 8, 11], "The": [0, 8, 9, 11], "basic": 0, "wai": 0, "i": [0, 2, 8, 11], "us": [0, 1, 2, 6], "http": [0, 3, 9, 11], "server": 0, "cd": 0, "8080": 0, "you": [0, 11], "can": [0, 2, 9, 11], "visit": 0, "page": 0, "your": [0, 11], "web": 0, "browser": 0, "url": 0, "localhost": 0, "introduciton": 1, "qualcomm": 1, "valid": 1, "model": [1, 2, 3], "come": [1, 2], "soon": [1, 2], "sdk": [1, 11], "github": [1, 9], "repositori": [1, 11], "guid": 1, "high": 1, "level": 1, "1": [1, 2, 4, 6, 8, 9], "qeffici": [1, 3], "cloud": [1, 2, 3], "infer": [1, 2], "2": [1, 4, 9], "execut": [1, 2, 9], "low": 1, "download": 1, "onnx": [1, 2], "export": [1, 2], "3": [1, 3, 4], "compil": 1, "ai": [1, 2, 3], "100": [1, 2, 3], "4": 1, "run": 1, "benchmark": 1, "detail": [1, 11], "kv": [1, 11], "cach": [1, 6, 8, 9, 11], "optim": [1, 2, 11], "export_hf_to_cloud_ai_100": [1, 11], "modul": [1, 2], "gener": [1, 6, 11], "text_generation_infer": [1, 11], "util": [1, 2, 11], "device_util": 1, "generate_input": 1, "run_util": 1, "modeling_attn_mask_util": 1, "modeling_output": 1, "modeling_util": 1, "train": [1, 2], "anywher": [1, 2], "how": [1, 2], "quadrupl": 1, "llm": [1, 2], "decod": [1, 2, 8, 11], "perform": [1, 2, 8, 11], "specul": [1, 2], "spd": 1, "microsc": 1, "mx": 1, "format": 1, "power": [1, 11], "acceler": 1, "larg": [1, 9], "languag": [1, 9], "2x": 1, "introduc": 1, "One": 1, "infinit": 1, "possibl": 1, "latest": 2, "new": [2, 9, 11], "support": [2, 3, 11], "more": [2, 8, 11], "popular": 2, "techniqu": 2, "like": [2, 11], "continu": 2, "batch": [2, 6, 8, 11], "05": 2, "2024": 2, "ad": [2, 9, 11], "mixtral": [2, 4], "8x7b": [2, 4], "mistral": [2, 4], "7b": [2, 4], "instruct": [2, 4], "v0": [2, 4], "04": 2, "initi": [2, 9, 11], "releas": 2, "seamless": 2, "pre": [2, 3, 9], "develop": [2, 11], "centric": 2, "toolchain": 2, "librari": [2, 3, 11], "provid": [2, 9, 11], "reimplement": 2, "block": [2, 9], "which": [2, 8, 11], "ar": [2, 9, 11], "function": 2, "highli": 2, "There": 2, "sever": 2, "directli": 2, "from": [2, 8, 9, 11], "origin": 2, "form": [2, 9], "deploy": 2, "readi": 2, "For": [2, 9, 11], "other": [2, 11], "comprehens": 2, "inspir": 2, "upon": [2, 11], "chang": [2, 8, 11], "need": [2, 11], "To": [2, 11], "": [2, 9], "typic": 2, "enabl": [2, 3, 6, 8, 11], "devic": [2, 3, 6, 8, 9, 11], "retent": [2, 8, 9], "intermedi": 2, "state": 2, "graph": 2, "kei": [2, 9], "oper": 2, "lower": 2, "precis": [2, 6, 8], "replac": [2, 11], "some": 2, "mathemat": 2, "equival": 2, "handl": 2, "underflow": 2, "overflow": [2, 11], "patcher": 2, "map": 2, "weight": 2, "updat": [2, 11], "sourc": [2, 3, 6, 8, 9], "sampl": [2, 6, 8, 11], "exampl": [2, 6, 8, 11], "applic": 2, "demo": 2, "notebook": 2, "unit": 2, "test": 2, "templat": 2, "It": [2, 8, 11], "mandatori": 2, "each": [2, 9], "pull": 2, "request": 2, "includ": 2, "If": [2, 3, 6, 8, 9, 11], "pr": 2, "should": [2, 3, 11], "success": 2, "post": [2, 9, 11], "part": 2, "pytorch": [2, 11], "onnxrt": 2, "exit": 2, "criteria": 2, "mse": 2, "between": 2, "output": [2, 8], "modifi": [2, 11], "ani": [2, 11], "common": 2, "all": [2, 8], "system": 3, "linux": 3, "o": [3, 11], "ubuntu": [3, 6], "rhel": 3, "aw": 3, "requisit": 3, "platform": [3, 8, 11], "app": 3, "multi": 3, "shard": 3, "bash": 3, "termin": 3, "zsh": 3, "device_group": [3, 6, 8, 11], "singl": [3, 11], "quot": 3, "e": [3, 6, 8], "g": [3, 6, 8], "0": [3, 6, 8, 9, 11], "donwload": 3, "sh": 3, "qeff": 3, "creat": [3, 11], "python": [3, 11], "virtual": 3, "env": 3, "activ": 3, "8": 3, "venv": 3, "qeff_env": 3, "bin": 3, "clone": 3, "repo": [3, 11], "com": [3, 9], "quic": 3, "effici": [3, 6, 8], "transform": [3, 6], "host": [3, 11], "machin": 3, "cli": 3, "api": [3, 9], "until": [3, 8], "we": [3, 11], "have": [3, 9, 11], "docker": 3, "integr": 3, "gpt2": [4, 6, 8, 11], "llama": 4, "8b": 4, "70b": 4, "chat": 4, "hf": [4, 11], "13b": 4, "codellama": 4, "34b": 4, "salesforc": [4, 11], "codegen25": 4, "mono_p": 4, "xgen": 4, "8k": 4, "mpt": 4, "falcon": 4, "40b": 4, "starcoder2": 4, "15b": 4, "phi": 4, "jai": 4, "30b": 4, "gpt": 4, "j": 4, "6b": 4, "chatglm2": 4, "baichuan2": 4, "click": 5, "here": 5, "main": [6, 8, 9, 11], "model_nam": [6, 8, 11], "str": [6, 8, 9], "num_cor": [6, 8, 11], "int": [6, 8, 9, 11], "prompt": [6, 8, 9, 11], "none": [6, 8, 9], "prompts_txt_file_path": [6, 11], "aic_enable_depth_first": [6, 8, 11], "bool": [6, 8, 9], "fals": [6, 8], "mo": [6, 8, 11], "cache_dir": [6, 11], "home": [1, 6], "amitraj": 6, "hf_token": [6, 8, 11], "batch_siz": [6, 8, 9, 11], "prompt_len": [6, 8, 9, 11], "32": [6, 8, 11], "ctx_len": [6, 8, 9, 11], "128": [6, 8, 11], "mxfp6": [6, 8, 11], "mxint8": [6, 8], "list": [6, 8, 9, 11], "param": [6, 8, 9], "hug": [6, 8, 11], "face": [6, 8, 11], "card": [6, 8, 11], "name": [6, 8, 11], "number": [6, 8, 9, 11], "core": [6, 8], "default": [6, 8, 11], "16": [6, 8, 11], "avail": [6, 8, 9], "option": [6, 8, 9, 11], "text": [6, 8], "pass": [6, 8, 11], "dure": [6, 8], "effort": [6, 8, 11], "reduc": [6, 8], "chip": [6, 8], "memori": [6, 8], "dir": [6, 11], "store": [6, 8], "huggingfac": [6, 8, 9, 11], "file": [6, 11], "token": [6, 8, 11], "access": [6, 8], "gate": [6, 8], "size": [6, 8, 11], "len": [6, 8], "maximum": [6, 8], "context": [6, 8], "length": [6, 8, 9], "id": [6, 8, 9], "comma": [6, 8], "separ": [6, 8], "multipl": [6, 8], "setup": [6, 8], "qpc_path": [6, 8, 11], "path": [6, 8, 11], "save": [6, 8, 11], "binari": [6, 8], "after": [6, 8, 9, 11], "type": [8, 11], "form_factor": [8, 9, 11], "nn": 8, "instanc": 8, "diffus": 8, "convert_to_cloud_bertstyl": 8, "model_class": 8, "onnx_dir_path": 8, "seq_len": 8, "input_str": [8, 9], "my": [8, 11], "return_path": [8, 11], "save_fp32_onnx": 8, "save_fp16_onnx": 8, "true": [8, 9, 11], "bertstyl": [8, 11], "approach": [8, 11], "No": 8, "prefil": [8, 11], "logic": 8, "everi": 8, "time": [8, 11], "comput": [8, 9, 11], "eo": 8, "max_length": 8, "hf_autotoken": 8, "prepar": 8, "input": [8, 11], "model_path": [8, 9], "where": 8, "load": 8, "locat": 8, "sequenc": [8, 9], "string": [8, 9, 11], "process": 8, "return": 8, "fp32": 8, "unclip": 8, "version": [8, 11], "fp16": [8, 11], "clip": [8, 11], "delet": 8, "convert_to_cloud_kvstyl": 8, "model_kv": [8, 11], "architectur": [8, 9, 11], "particularli": [8, 11], "suitabl": 8, "autoregress": [8, 9], "task": 8, "involv": 8, "one": [8, 9, 11], "contextu": 8, "inform": 8, "earlier": 8, "crucial": 8, "predict": [8, 9], "next": 8, "inclus": 8, "enhanc": 8, "computation": 8, "constant": [8, 11], "seq_length": 8, "qualcomm_efficient_convert": [8, 11], "class": 8, "onnx_path": [8, 11], "given": 8, "config": [8, 9, 11], "base_path": [8, 11], "cloud_ai_100_exec_kv_help": 8, "pretrainedtoken": 8, "pretrainedtokenizerfast": 8, "input_len": 8, "generation_len": 8, "device_id": [8, 11], "enable_debug_log": 8, "stream": 8, "write_io_dir": 8, "get": 8, "chunk": 8, "debug": 8, "log": 8, "streamer": 8, "them": 8, "autom": 8, "print": [8, 11], "stat": [8, 11], "latency_stats_bertstyl": 8, "get_available_device_id": 9, "check": [9, 11], "inputhandl": 9, "object": 9, "prepare_cloud_ai_100_input": 9, "n_layer": 9, "padding_shap": 9, "layer": 9, "shape": 9, "past": 9, "dict": 9, "input_id": 9, "position_id": 9, "attention_mask": 9, "past_key_valu": 9, "cache_index": 9, "prepare_ort_input": 9, "prepare_pytorch_input": 9, "update_cloud_ai_100_input": 9, "current": 9, "previou": 9, "sinc": 9, "skip": [9, 11], "update_ort_input": 9, "ort_output": 9, "ort": 9, "update_pytorch_input": 9, "pt_output": 9, "apirunn": 9, "run_hf_model_on_pytorch": 9, "model_hf": [9, 11], "generated_id": 9, "ndarrai": 9, "run_kv_model_on_cloud_ai_100": 9, "run_kv_model_on_ort": 9, "run_kv_model_on_pytorch": 9, "run_ort_sess": 9, "capi": 9, "onnxruntime_inference_collect": 9, "inferencesess": 9, "qeffattentionmaskconvert": 9, "is_caus": 9, "sliding_window": 9, "longtensor": 9, "attentionmaskconvert": 9, "A": 9, "attent": 9, "mask": 9, "allow": 9, "causal": 9, "4d": 9, "slide": 9, "window": 9, "convert": 9, "2d": 9, "query_length": 9, "key_value_length": 9, "to_4d": 9, "attention_mask_2d": 9, "dtype": 9, "expand": 9, "bsz": 9, "head_dim": 9, "neg": 9, "bia": 9, "attend": 9, "posit": 9, "also": [9, 11], "copi": 9, "blob": 9, "src": 9, "py": 9, "onli": 9, "differ": [9, 11], "add": 9, "arg": [9, 11], "idx": 9, "qeffbasemodeloutputwithpast": 9, "last_hidden_st": 9, "floattensor": 9, "tupl": 9, "hidden_st": 9, "attention_mask_retainedst": 9, "booltensor": 9, "modeloutput": 9, "mai": 9, "speed": 9, "up": 9, "sequenti": 9, "torch": [9, 11], "sequence_length": 9, "hidden_s": 9, "hidden": 9, "last": 9, "when": [9, 11], "use_cach": [9, 11], "num_head": 9, "embed_size_per_head": 9, "is_encoder_decod": 9, "addit": 9, "encoder_sequence_length": 9, "self": 9, "cross": 9, "see": 9, "output_hidden_st": 9, "embed": 9, "ha": 9, "an": 9, "plu": 9, "output_attent": 9, "softmax": 9, "averag": 9, "head": 9, "qeffbasemodeloutputwithpastandcrossattent": 9, "cross_attent": 9, "add_cross_attent": 9, "qeffcausallmoutputwithcrossattent": 9, "loss": 9, "logit": 9, "label": 9, "vocab_s": 9, "score": 9, "vocabulari": 9, "befor": 9, "encod": 9, "set": [9, 11], "relev": 9, "is_decod": 9, "qeffcausallmoutputwithpast": 9, "qeffmoecausallmoutputwithpast": 9, "aux_loss": 9, "router_logit": 9, "mixtur": 9, "expert": 9, "spars": 9, "output_router_prob": 9, "add_router_prob": 9, "num_expert": 9, "raw": 9, "router": 9, "logti": 9, "moe": 9, "term": 9, "auxiliari": 9, "qeffmoemodeloutputwithpast": 9, "potenti": 9, "modelarchitectur": 9, "alia": 9, "field": 9, "get_params_hash": 9, "replace_module_with_qeff_lay": 9, "factor": 9, "configur": 9, "edg": 9, "wa": 11, "design": 11, "goal": 11, "onboard": 11, "straightforward": 11, "while": 11, "leverag": 11, "complet": 11, "achiev": 11, "abstract": 11, "awai": 11, "complex": 11, "offer": 11, "simpler": 11, "interfac": 11, "thei": 11, "re": 11, "ideal": 11, "prototyp": 11, "technologi": 11, "want": 11, "minim": 11, "code": 11, "user": [1, 11], "friendli": 11, "granular": 11, "control": 11, "custom": 11, "necessari": 11, "These": 11, "who": 11, "try": 11, "own": 11, "implement": 11, "In": 11, "summari": 11, "choos": 11, "simplic": 11, "eas": 11, "opt": 11, "fine": 11, "tune": 11, "advanc": 11, "e2": 11, "take": 11, "model_card": 11, "along": 11, "doe": 11, "everyth": 11, "go": 11, "verifi": 11, "cpu": 11, "Its": 11, "stage": 11, "qpc": 11, "found": 11, "out": 11, "help": 11, "menu": 11, "either": 11, "seper": 11, "pipe": 11, "symbol": 11, "below": 11, "flat": 11, "earth": 11, "theori": 11, "belief": 11, "sun": 11, "rise": 11, "Or": 11, "present": 11, "folder": 11, "onc": 11, "now": 11, "precompil": 11, "qeff_model": 11, "qpc_16cores_1bs_32pl_128cl_1devices_mxfp6": 11, "mq": 11, "just": 11, "group": 11, "t": 11, "fly": 11, "soc": 11, "codegen": 11, "2b": 11, "mono": 11, "def": 11, "fibonacci": 11, "n": 11, "qpc_16cores_1bs_32pl_128cl_2devices_mxfp6": 11, "binary_search": 11, "arrai": 11, "np": 11, "k": 11, "disabl": 11, "tensor": 11, "slice": 11, "1024": 11, "xyz": 11, "note": 11, "preffer": 11, "respect": 11, "orign": 11, "import": 11, "modeling_gpt2": 11, "gpt2lmheadmodel": 11, "autotoken": 11, "hf_download": 11, "pleas": 11, "uncom": 11, "appropri": 11, "case": 11, "don": 11, "environ": 11, "transformers_cach": 11, "local": 11, "mnt": 11, "workspac": 11, "hf_cach": 11, "root_dir": 11, "dirnam": 11, "abspath": 11, "co": 11, "xl": 11, "similar": 11, "correspond": 11, "lib": 11, "model_hf_path": 11, "repo_id": 11, "ignore_pattren": 11, "ot": 11, "md": 11, "tflite": 11, "pdf": 11, "from_pretrain": 11, "eval": 11, "f": 11, "easi": 11, "model_transform": 11, "framework": 11, "both": 11, "variat": 11, "onnxruntim": 11, "v": 11, "Then": 11, "custom_io": 11, "yaml": 11, "style": 11, "flag": 11, "do": 11, "w": 11, "unoptim": 11, "recommend": 11, "better": 11, "defin": 11, "hub": 11, "trust_remote_cod": 11, "trust": 11, "padding_sid": 11, "left": 11, "generated_qpc_path": 11, "14": 11, "tok": 11, "sec": 11, "cloud_ai_100_exec_kv": 11, "get_compilation_batch_s": 11, "latenc": 11, "greedi": 11, "www": [], "product": [], "processor": [], "artifici": [], "intellig": [], "ocp": 1, "specif": 1, "5": []}, "objects": {"QEfficient.cloud": [[6, 0, 0, "-", "execute"], [6, 0, 0, "-", "infer"]], "QEfficient.cloud.execute": [[6, 1, 1, "", "main"]], "QEfficient.cloud.infer": [[6, 1, 1, "", "main"]], "QEfficient.exporter": [[8, 0, 0, "-", "export_hf_to_cloud_ai_100"]], "QEfficient.exporter.export_hf_to_cloud_ai_100": [[8, 1, 1, "", "convert_to_cloud_bertstyle"], [8, 1, 1, "", "convert_to_cloud_kvstyle"], [8, 1, 1, "", "qualcomm_efficient_converter"]], "QEfficient.generation": [[8, 0, 0, "-", "text_generation_inference"]], "QEfficient.generation.text_generation_inference": [[8, 1, 1, "", "cloud_ai_100_exec_kv_helper"], [8, 1, 1, "", "latency_stats_bertstyle"]], "QEfficient.transformers": [[9, 0, 0, "-", "modeling_attn_mask_utils"], [9, 0, 0, "-", "modeling_outputs"], [9, 0, 0, "-", "modeling_utils"]], "QEfficient.transformers.modeling_attn_mask_utils": [[9, 2, 1, "", "QEffAttentionMaskConverter"]], "QEfficient.transformers.modeling_attn_mask_utils.QEffAttentionMaskConverter": [[9, 3, 1, "", "cache_index"], [9, 3, 1, "", "is_causal"], [9, 3, 1, "", "sliding_window"], [9, 4, 1, "", "to_4d"]], "QEfficient.transformers.modeling_outputs": [[9, 2, 1, "", "QEffBaseModelOutputWithPast"], [9, 2, 1, "", "QEffBaseModelOutputWithPastAndCrossAttentions"], [9, 2, 1, "", "QEffCausalLMOutputWithCrossAttentions"], [9, 2, 1, "", "QEffCausalLMOutputWithPast"], [9, 2, 1, "", "QEffMoeCausalLMOutputWithPast"], [9, 2, 1, "", "QEffMoeModelOutputWithPast"]], "QEfficient.transformers.modeling_utils": [[9, 2, 1, "", "ModelArchitectures"], [9, 1, 1, "", "get_params_hash"], [9, 1, 1, "", "replace_module_with_qeff_layers"], [9, 1, 1, "", "transform"]], "QEfficient.transformers.modeling_utils.ModelArchitectures": [[9, 3, 1, "", "architectures"]], "QEfficient.utils": [[9, 0, 0, "-", "device_utils"], [9, 0, 0, "-", "generate_inputs"], [9, 0, 0, "-", "run_utils"]], "QEfficient.utils.device_utils": [[9, 1, 1, "", "get_available_device_id"]], "QEfficient.utils.generate_inputs": [[9, 2, 1, "", "InputHandler"]], "QEfficient.utils.generate_inputs.InputHandler": [[9, 4, 1, "", "prepare_cloud_ai_100_inputs"], [9, 4, 1, "", "prepare_ort_inputs"], [9, 4, 1, "", "prepare_pytorch_inputs"], [9, 4, 1, "", "update_cloud_ai_100_inputs"], [9, 4, 1, "", "update_ort_inputs"], [9, 4, 1, "", "update_pytorch_inputs"]], "QEfficient.utils.run_utils": [[9, 2, 1, "", "ApiRunner"]], "QEfficient.utils.run_utils.ApiRunner": [[9, 4, 1, "", "run_hf_model_on_pytorch"], [9, 4, 1, "", "run_kv_model_on_cloud_ai_100"], [9, 4, 1, "", "run_kv_model_on_ort"], [9, 4, 1, "", "run_kv_model_on_pytorch"], [9, 4, 1, "", "run_ort_session"]]}, "objtypes": {"0": "py:module", "1": "py:function", "2": "py:class", "3": "py:attribute", "4": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "function", "Python function"], "2": ["py", "class", "Python class"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "method", "Python method"]}, "titleterms": {"doc": 0, "build": 0, "preview": 0, "local": 0, "welcom": 1, "effici": [1, 2, 5], "transform": [1, 2, 5, 8, 9, 11], "document": 1, "get": 1, "start": [1, 11], "instal": [1, 3], "quick": [1, 11], "python": 1, "api": [1, 5, 6, 8, 11, 12], "blog": 1, "refer": [1, 12], "introduciton": 2, "qualcomm": [2, 5, 12], "requir": 3, "us": [3, 5, 8, 9, 11], "sdk": [3, 5, 12], "github": 3, "repositori": 3, "valid": 4, "model": [4, 5, 6, 8, 9, 11], "come": 4, "soon": 4, "train": 5, "anywher": 5, "infer": [5, 6, 11], "cloud": [5, 6, 7, 8, 9, 11, 12], "ai": [5, 6, 7, 8, 9, 11, 12], "100": [5, 6, 7, 8, 9, 11], "how": 5, "quadrupl": 5, "llm": 5, "decod": [5, 9], "perform": 5, "specul": 5, "spd": 5, "microsc": [5, 12], "mx": [5, 12], "format": [5, 12], "power": 5, "acceler": 5, "larg": 5, "languag": 5, "2x": 5, "introduc": 5, "One": 5, "infinit": 5, "possibl": 5, "high": [6, 11], "level": [6, 8, 11], "qeffici": [6, 8, 9, 11], "command": 6, "download": [6, 11, 12], "from": 6, "hf": 6, "optim": [6, 7, 9], "compil": [6, 8, 11], "execut": [6, 8, 11], "aic": 6, "run": [6, 9, 11], "platform": 6, "detail": [7, 10], "kv": [7, 8, 9], "cach": 7, "low": [8, 11], "librari": 8, "export": [8, 11], "export_hf_to_cloud_ai_100": 8, "modul": [8, 9], "convert": 8, "torch": 8, "bert": 8, "style": 8, "onnx": [8, 9, 11], "gener": 8, "text_generation_infer": 8, "qpc": 8, "file": 8, "cpu": 8, "util": 9, "device_util": 9, "generate_input": 9, "function": 9, "respons": 9, "creat": 9, "prefil": 9, "stage": 9, "numpi": 9, "input": 9, "onnxrt": 9, "tensor": 9, "pytorch": 9, "updat": 9, "run_util": 9, "return": 9, "output": 9, "token": 9, "onnxruntim": 9, "session": 9, "given": 9, "pass": 9, "retain": 9, "state": 9, "next": 9, "iter": 9, "modeling_attn_mask_util": 9, "modeling_output": 9, "modeling_util": 9, "hash": 9, "all": 9, "paramet": 9, "valu": 9, "i": 9, "e": 9, "weight": 9, "sha256": 9, "algo": 9, "replac": 9, "nn": 9, "class": 9, "optmiz": 9, "qeff": 9, "place": 9, "some": 9, "method": 9, "equival": 9, "perfrom": 10, "guid": [11, 12], "1": 11, "2": 11, "3": 11, "4": 11, "benchmark": 11, "http": [], "www": [], "com": [], "product": [], "technologi": [], "processor": [], "artifici": [], "intellig": [], "home": 12, "user": 12, "ocp": 12, "specif": 12, "5": []}, "envversion": {"sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 58}, "alltitles": {"Docs": [[0, "docs"]], "Build the docs": [[0, "build-the-docs"]], "Preview the docs locally": [[0, "preview-the-docs-locally"]], "Welcome to Efficient-Transformers Documentation!": [[1, "welcome-to-efficient-transformers-documentation"]], "Getting Started": [[1, null]], "Installation": [[1, null], [3, "installation"]], "Quick start": [[1, null]], "Python API": [[1, null]], "Blogs": [[1, null]], "Reference": [[1, null]], "Introduciton Qualcomm Efficient-Transformers": [[2, "introduciton-qualcomm-efficient-transformers"]], "Requirements": [[3, "requirements"]], "Using SDK": [[3, "using-sdk"]], "Using GitHub Repository": [[3, "using-github-repository"]], "Validated Models": [[4, "validated-models"]], "Models Coming Soon": [[4, "models-coming-soon"]], "Train anywhere, Infer on Qualcomm Cloud AI 100": [[5, "train-anywhere-infer-on-qualcomm-cloud-ai-100"]], "How to Quadruple LLM Decoding Performance with Speculative Decoding (SpD) and Microscaling (MX) Formats on Qualcomm\u00ae Cloud AI 100": [[5, "how-to-quadruple-llm-decoding-performance-with-speculative-decoding-spd-and-microscaling-mx-formats-on-qualcomm-cloud-ai-100"]], "Power-efficient acceleration for large language models \u2013 Qualcomm Cloud AI SDK": [[5, "power-efficient-acceleration-for-large-language-models-qualcomm-cloud-ai-sdk"]], "Qualcomm Cloud AI 100 Accelerates Large Language Model Inference by ~2x Using Microscaling (Mx) Formats": [[5, "qualcomm-cloud-ai-100-accelerates-large-language-model-inference-by-2x-using-microscaling-mx-formats"]], "Qualcomm Cloud AI Introduces Efficient Transformers: One API, Infinite Possibilities": [[5, "qualcomm-cloud-ai-introduces-efficient-transformers-one-api-infinite-possibilities"]], "Details on KV Cache Optimization for Cloud AI 100": [[7, "details-on-kv-cache-optimization-for-cloud-ai-100"]], "Utilities": [[9, "utilities"]], "QEfficient.utils.device_utils module": [[9, "module-QEfficient.utils.device_utils"]], "QEfficient.utils.generate_inputs module": [[9, "module-QEfficient.utils.generate_inputs"]], "Function responsible for creating Prefill stage numpy inputs for ONNX model to be run on Cloud AI 100.": [[9, "function-responsible-for-creating-prefill-stage-numpy-inputs-for-onnx-model-to-be-run-on-cloud-ai-100"]], "Function responsible for creating Prefill stage numpy inputs for ONNX model to be run on ONNXRT.": [[9, "function-responsible-for-creating-prefill-stage-numpy-inputs-for-onnx-model-to-be-run-on-onnxrt"]], "Function responsible for creating Prefill stage tensor inputs for PyTorch model.": [[9, "function-responsible-for-creating-prefill-stage-tensor-inputs-for-pytorch-model"]], "Function responsible for updating Prefill stage inputs to create inputs for decode stage inputs for ONNX model to be run on ONNXRT.": [[9, "function-responsible-for-updating-prefill-stage-inputs-to-create-inputs-for-decode-stage-inputs-for-onnx-model-to-be-run-on-onnxrt"]], "Function responsible for updating Prefill stage inputs to create inputs for decode stage inputs for PyTorch model.": [[9, "function-responsible-for-updating-prefill-stage-inputs-to-create-inputs-for-decode-stage-inputs-for-pytorch-model"]], "QEfficient.utils.run_utils module": [[9, "module-QEfficient.utils.run_utils"]], "Function responsible for running ONNX model on Cloud AI 100 and return the output tokens": [[9, "function-responsible-for-running-onnx-model-on-cloud-ai-100-and-return-the-output-tokens"]], "Function responsible for running ONNX model on onnxruntime and return the output tokens": [[9, "function-responsible-for-running-onnx-model-on-onnxruntime-and-return-the-output-tokens"]], "Function responsible for running KV PyTorch model and return the output tokens": [[9, "function-responsible-for-running-kv-pytorch-model-and-return-the-output-tokens"]], "Function responsible for running onnxrt session with given inputs and passing retained state outputs to be used for next iteration inputs": [[9, "function-responsible-for-running-onnxrt-session-with-given-inputs-and-passing-retained-state-outputs-to-be-used-for-next-iteration-inputs"]], "QEfficient.transformers.modeling_attn_mask_utils module": [[9, "module-QEfficient.transformers.modeling_attn_mask_utils"]], "QEfficient.transformers.modeling_outputs module": [[9, "module-QEfficient.transformers.modeling_outputs"]], "QEfficient.transformers.modeling_utils module": [[9, "module-QEfficient.transformers.modeling_utils"]], "Creates a Hash of all the parameters values i.e. weights using SHA256 algo.": [[9, "creates-a-hash-of-all-the-parameters-values-i-e-weights-using-sha256-algo"]], "Replaces the transformers nn.Module classes with optmized QEff classes in place.": [[9, "replaces-the-transformers-nn-module-classes-with-optmized-qeff-classes-in-place"]], "Replaces some Transformers\u2019 methods for equivalent methods optimized for AI 100.": [[9, "replaces-some-transformers-methods-for-equivalent-methods-optimized-for-ai-100"]], "Perfromance details": [[10, "perfromance-details"]], "Quick Start Guide": [[11, "quick-start-guide"]], "Using High Level API": [[11, "using-high-level-api"]], "1. Use QEfficient.cloud.infer": [[11, "use-qefficient-cloud-infer"]], "2. Use of QEfficient.cloud.execute": [[11, "use-of-qefficient-cloud-execute"]], "Using Low Level API": [[11, "using-low-level-api"]], "1.  Model download and transform": [[11, "model-download-and-transform"]], "2. ONNX export of transformed model": [[11, "onnx-export-of-transformed-model"]], "3. Compile on Cloud AI 100": [[11, "compile-on-cloud-ai-100"]], "4. Run Benchmark": [[11, "run-benchmark"]], "Low level API": [[8, "low-level-api"]], "QEfficient.transform": [[8, "module-QEfficient"]], "Low level apis in library": [[8, "low-level-apis-in-library"]], "QEfficient.exporter.export_hf_to_cloud_ai_100 module": [[8, "module-QEfficient.exporter.export_hf_to_cloud_ai_100"]], "API to convert torch Bert style and KV style model to ONNX.": [[8, "api-to-convert-torch-bert-style-and-kv-style-model-to-onnx"]], "QEfficient.cloud.compile": [[8, "module-QEfficient.cloud.compile"]], "QEfficient.generation.text_generation_inference module": [[8, "module-QEfficient.generation.text_generation_inference"]], "API to execute QEfficient transformed ONNX model on Cloud AI 100 using compiled QPC file.": [[8, "api-to-execute-qefficient-transformed-onnx-model-on-cloud-ai-100-using-compiled-qpc-file"]], "API to execute ONNX model on CPU.": [[8, "api-to-execute-onnx-model-on-cpu"]], "High Level API": [[6, "high-level-api"]], "QEfficient.cloud.infer": [[6, "module-QEfficient.cloud.infer"]], "Inference command, the model will be downloaded from HF, optimized, compiled, executed on AIC.": [[6, "inference-command-the-model-will-be-downloaded-from-hf-optimized-compiled-executed-on-aic"]], "QEfficient.cloud.execute": [[6, "module-QEfficient.cloud.execute"]], "API to run the model on Cloud AI 100 platform.": [[6, "api-to-run-the-model-on-cloud-ai-100-platform"]], "Qualcomm Cloud AI home": [[12, "qualcomm-cloud-ai-home"]], "Qualcomm Cloud AI SDK download": [[12, "qualcomm-cloud-ai-sdk-download"]], "Qualcomm Cloud AI API reference": [[12, "qualcomm-cloud-ai-api-reference"]], "User Guide": [[12, "user-guide"]], "OCP Microscaling Formats (MX) Specification": [[12, "ocp-microscaling-formats-mx-specification"]]}, "indexentries": {}})